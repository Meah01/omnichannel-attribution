name: Journey Assembly Master Orchestration

on:
  schedule:
    # Every 3 days at 3:00 AM Amsterdam time (1:00 AM UTC)
    - cron: '0 1 */3 * *'
  workflow_dispatch:
    inputs:
      force_run:
        description: 'Force run even if system is disabled'
        required: false
        default: 'false'
        type: boolean
      days_to_collect:
        description: 'Number of days of data to collect'
        required: false
        default: '3'
        type: string

env:
  # System control environment variables
  JOURNEY_ASSEMBLY_ENABLED: ${{ vars.JOURNEY_ASSEMBLY_ENABLED || 'true' }}
  IMMEDIATE_STOP: ${{ vars.IMMEDIATE_STOP || 'false' }}
  
  # API endpoints
  JOURNEY_ASSEMBLER_URL: ${{ vars.JOURNEY_ASSEMBLER_URL || 'http://localhost:8008' }}
  
  # Generator endpoints  
  GOOGLE_ADS_API: ${{ vars.GOOGLE_ADS_API || 'http://localhost:8000' }}
  FACEBOOK_ADS_API: ${{ vars.FACEBOOK_ADS_API || 'http://localhost:8001' }}
  EMAIL_MARKETING_API: ${{ vars.EMAIL_MARKETING_API || 'http://localhost:8002' }}
  LINKEDIN_ADS_API: ${{ vars.LINKEDIN_ADS_API || 'http://localhost:8003' }}
  EVENTS_API: ${{ vars.EVENTS_API || 'http://localhost:8004' }}
  WEBSITE_SEO_API: ${{ vars.WEBSITE_SEO_API || 'http://localhost:8005' }}
  APP_STORE_API: ${{ vars.APP_STORE_API || 'http://localhost:8006' }}
  ORGANIC_SOCIAL_API: ${{ vars.ORGANIC_SOCIAL_API || 'http://localhost:8007' }}

jobs:
  check-system-status:
    name: Check System Status
    runs-on: ubuntu-latest
    outputs:
      system_enabled: ${{ steps.status-check.outputs.enabled }}
      processing_status: ${{ steps.status-check.outputs.status }}
    
    steps:
      - name: Check Journey Assembly Status
        id: status-check
        run: |
          # Check if system is enabled via environment variables
          if [[ "${{ env.JOURNEY_ASSEMBLY_ENABLED }}" == "true" && "${{ env.IMMEDIATE_STOP }}" == "false" ]]; then
            echo "enabled=true" >> $GITHUB_OUTPUT
            echo "status=ready" >> $GITHUB_OUTPUT
            echo "Journey Assembly System: ENABLED"
          else
            echo "enabled=false" >> $GITHUB_OUTPUT  
            echo "status=disabled" >> $GITHUB_OUTPUT
            echo " Journey Assembly System: DISABLED"
          fi
          
          # Override for manual force run
          if [[ "${{ inputs.force_run }}" == "true" ]]; then
            echo "enabled=true" >> $GITHUB_OUTPUT
            echo "status=force_enabled" >> $GITHUB_OUTPUT
            echo "Force run enabled - overriding system status"
          fi

      - name: Check Journey Assembler API Health
        if: steps.status-check.outputs.enabled == 'true'
        run: |
          echo " Checking Journey Assembler API health..."
          
          # Try to reach the assembler API (if running locally, this would need to be adapted)
          # For portfolio demonstration, we'll simulate the check
          echo "Journey Assembler API: Healthy"
          echo "System ready for data collection"

  data-collection:
    name: Collect Data from All Generators  
    runs-on: ubuntu-latest
    needs: check-system-status
    if: needs.check-system-status.outputs.system_enabled == 'true'
    
    strategy:
      matrix:
        channel: [
          { name: 'google_ads', api: 'GOOGLE_ADS_API', port: '8000' },
          { name: 'facebook_ads', api: 'FACEBOOK_ADS_API', port: '8001' },
          { name: 'email_marketing', api: 'EMAIL_MARKETING_API', port: '8002' },
          { name: 'linkedin_ads', api: 'LINKEDIN_ADS_API', port: '8003' },
          { name: 'events', api: 'EVENTS_API', port: '8004' },
          { name: 'content_website_seo', api: 'WEBSITE_SEO_API', port: '8005' },
          { name: 'app_store', api: 'APP_STORE_API', port: '8006' },
          { name: 'organic_social', api: 'ORGANIC_SOCIAL_API', port: '8007' }
        ]
      fail-fast: false # Continue other channels even if one fails
      
    outputs:
      collection_results: ${{ steps.collect-data.outputs.results }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Dependencies
        run: |
          pip install requests python-dateutil

      - name: Calculate Collection Period
        id: dates
        run: |
          python3 << 'EOF'
          from datetime import datetime, timedelta
          import os
          
          # Calculate date range
          days_back = int("${{ inputs.days_to_collect || '3' }}")
          end_date = datetime.now()
          start_date = end_date - timedelta(days=days_back)
          
          # Format for API calls
          start_str = start_date.strftime('%Y-%m-%d')
          end_str = end_date.strftime('%Y-%m-%d')
          
          print(f"ðŸ“… Collection Period: {start_str} to {end_str}")
          
          # Set GitHub outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"start_date={start_str}\n")
              f.write(f"end_date={end_str}\n")
              f.write(f"days_collected={days_back}\n")
          EOF

      - name: Collect Data from ${{ matrix.channel.name }}
        id: collect-data
        env:
          CHANNEL_API_URL: ${{ env[matrix.channel.api] }}
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          from datetime import datetime
          
          # API configuration
          channel_name = "${{ matrix.channel.name }}"
          api_url = os.getenv('CHANNEL_API_URL', f"http://localhost:${{ matrix.channel.port }}")
          
          # Collection parameters
          start_date = "${{ steps.dates.outputs.start_date }}"
          end_date = "${{ steps.dates.outputs.end_date }}"
          max_records = 10000
          
          print(f"Collecting data from {channel_name.upper()} API...")
          print(f"API URL: {api_url}")
          print(f"Period: {start_date} to {end_date}")
          
          # Prepare API request
          if channel_name == "content_website_seo":
              endpoint = f"{api_url}/ga4/data"
          else:
              endpoint = f"{api_url}/data"
          
          payload = {
              "start_date": start_date,
              "end_date": end_date,
              "max_records": max_records
          }
          
          try:
              # For portfolio demonstration - simulate API call
              # In real implementation, this would make actual HTTP requests
              print(f"POST {endpoint}")
              print(f"Payload: {json.dumps(payload, indent=2)}")
              
              # Simulate successful collection
              touchpoints_collected = 2500  # Simulated count
              
              print(f"âœ… Successfully collected {touchpoints_collected} touchpoints from {channel_name}")
              
              # Create results for next step
              results = {
                  "channel": channel_name,
                  "touchpoints_collected": touchpoints_collected,
                  "status": "success",
                  "api_url": endpoint,
                  "collection_period": f"{start_date} to {end_date}"
              }
              
              # Save results
              with open(f"{channel_name}_results.json", "w") as f:
                  json.dump(results, f, indent=2)
              
              # Set GitHub output
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"results={json.dumps(results)}\n")
                  f.write(f"touchpoints_collected={touchpoints_collected}\n")
                  f.write(f"status=success\n")
                  
          except Exception as e:
              print(f"âŒ Error collecting data from {channel_name}: {str(e)}")
              
              error_results = {
                  "channel": channel_name,
                  "touchpoints_collected": 0,
                  "status": "error", 
                  "error": str(e)
              }
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"results={json.dumps(error_results)}\n")
                  f.write(f"touchpoints_collected=0\n")
                  f.write(f"status=error\n")
          EOF

      - name: Upload Collection Results
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.channel.name }}-collection-results
          path: ${{ matrix.channel.name }}_results.json
          retention-days: 7

  journey-assembly:
    name: Assemble Customer Journeys
    runs-on: ubuntu-latest
    needs: [check-system-status, data-collection]
    if: needs.check-system-status.outputs.system_enabled == 'true'
    
    outputs:
      journeys_assembled: ${{ steps.assembly.outputs.journeys_count }}
      assembly_status: ${{ steps.assembly.outputs.status }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download All Collection Results
        uses: actions/download-artifact@v4
        with:
          pattern: "*-collection-results"
          merge-multiple: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Dependencies
        run: |
          pip install requests python-dateutil

      - name: Send Data to Journey Assembler
        id: send-to-assembler
        run: |
          python3 << 'EOF'
          import json
          import glob
          import requests
          import os
          
          assembler_url = "${{ env.JOURNEY_ASSEMBLER_URL }}"
          
          print("ðŸ“¨ Sending collected data to Journey Assembler...")
          
          # Process each channel's results
          total_touchpoints = 0
          channels_processed = 0
          
          for results_file in glob.glob("*_results.json"):
              try:
                  with open(results_file, 'r') as f:
                      results = json.load(f)
                  
                  channel_name = results['channel']
                  touchpoints = results.get('touchpoints_collected', 0)
                  
                  if results['status'] == 'success' and touchpoints > 0:
                      print(f"ðŸ“¤ Sending {touchpoints} touchpoints from {channel_name} to assembler...")
                      
                      # For portfolio demonstration - simulate API call to assembler
                      endpoint = f"{assembler_url}/ingest/{channel_name}"
                      print(f"POST {endpoint}")
                      
                      total_touchpoints += touchpoints
                      channels_processed += 1
                      
                      print(f"Successfully sent {channel_name} data to assembler")
                  else:
                      print(f"Skipping {channel_name} - no data or error status")
                      
              except Exception as e:
                  print(f"Error processing {results_file}: {str(e)}")
          
          print(f"Summary: {total_touchpoints} total touchpoints from {channels_processed} channels")
          
          # Set outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"total_touchpoints={total_touchpoints}\n")
              f.write(f"channels_processed={channels_processed}\n")
          EOF

      - name: Trigger Journey Assembly
        id: assembly
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          import uuid
          from datetime import datetime, timedelta
          import random
          
          assembler_url = "${{ env.JOURNEY_ASSEMBLER_URL }}"
          
          print("ðŸ”„ Triggering journey assembly process...")
          
          # Trigger batch processing
          endpoint = f"{assembler_url}/webhooks/n8n-trigger"
          
          try:
              # For portfolio demonstration - simulate the assembly process matching assembler output format
              print(f"POST {endpoint}")
              
              # Generate realistic journey data in assembler format
              journeys_count = 100  # Limit for demo
              
              salesforce_ready_data = []
              
              for i in range(journeys_count):
                  # Generate UUID-based journey ID matching assembler format
                  journey_uuid = uuid.uuid4().hex[:12]
                  journey_id = f"journey_{journey_uuid}"
                  
                  # Generate customer ID with UUID
                  customer_uuid = uuid.uuid4().hex[:12]
                  customer_id = f"customer_{customer_uuid}"
                  
                  # Realistic journey parameters
                  customer_type = "B2B" if i % 4 == 0 else "B2C"
                  converted = i % 6 == 0
                  
                  journey_start = datetime.now() - timedelta(days=random.randint(1, 30))
                  journey_duration = random.randint(1, 14) if customer_type == "B2C" else random.randint(3, 45)
                  journey_end = journey_start + timedelta(days=journey_duration)
                  
                  num_touchpoints = random.randint(2, 6) if customer_type == "B2C" else random.randint(4, 12)
                  
                  # Generate channel sequence
                  channels = [
                      "google_ads", "facebook_ads", "linkedin_ads", "email_marketing",
                      "content_website_seo", "app_store", "events", "organic_social"
                  ]
                  
                  selected_channels = random.sample(channels, min(num_touchpoints, len(channels)))
                  
                  # Create journey wrapper matching assembler format
                  journey_wrapper = {
                      "Customer_Journey__c": {
                          "Name": f"Journey {journey_id}",
                          "Customer_ID__c": customer_id,
                          "Journey_Start_Date__c": journey_start.strftime('%Y-%m-%dT%H:%M:%SZ'),
                          "Journey_End_Date__c": journey_end.strftime('%Y-%m-%dT%H:%M:%SZ'),
                          "Total_Touchpoints__c": num_touchpoints,
                          "Converted__c": converted,
                          "Conversion_Value__c": round(random.uniform(50, 500), 2) if converted else 0.0,
                          "Journey_Duration_Days__c": journey_duration,
                          "Customer_Type__c": customer_type,
                          "Confidence_Score__c": round(random.uniform(0.6, 0.95), 2),
                          "Channel_Sequence__c": ", ".join(selected_channels),
                          "Synergistic_Patterns__c": "google_ads -> content_website_seo" if "google_ads" in selected_channels and "content_website_seo" in selected_channels else ""
                      },
                      "Touchpoints": []
                  }
                  
                  # Generate touchpoints
                  for tp_idx in range(num_touchpoints):
                      tp_time = journey_start + timedelta(
                          seconds=int((journey_end - journey_start).total_seconds() * tp_idx / (num_touchpoints - 1))
                      )
                      
                      # Generate UUID-based touchpoint ID
                      tp_uuid = uuid.uuid4().hex[:8]
                      touchpoint_id = f"tp_{tp_uuid}"
                      
                      touchpoint = {
                          "Name": f"Touchpoint {touchpoint_id}",
                          "Channel__c": selected_channels[tp_idx % len(selected_channels)],
                          "Touchpoint_Timestamp__c": tp_time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                          "Campaign_ID__c": f"campaign_{random.randint(1000, 9999)}",
                          "Device_Type__c": random.choice(["Mobile", "Desktop", "Tablet"]),
                          "Stage__c": random.choice(["Awareness", "Interest", "Consideration", "Conversion"]),
                          "Conversion_Value__c": round(random.uniform(0, 100), 2) if random.random() > 0.8 else 0.0
                      }
                      
                      journey_wrapper["Touchpoints"].append(touchpoint)
                  
                  salesforce_ready_data.append(journey_wrapper)
              
              # Create assembly results matching assembler response format
              assembly_response = {
                  "status": "success",
                  "processed_journeys": len(salesforce_ready_data),
                  "salesforce_ready_data": salesforce_ready_data
              }
              
              print(f"Successfully assembled {len(salesforce_ready_data)} customer journeys")
              
              # Save assembly results
              with open("journey_assembly_results.json", "w") as f:
                  json.dump(assembly_response, f, indent=2)
              
              print("Journey Assembly Results:")
              print(f"   Journeys: {len(salesforce_ready_data)}")
              print(f"   Format: Customer Journey Assembler compatible")
              print(f"   IDs: UUID-based (journey_abc123, customer_def456)")
              
              # Set GitHub outputs
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"journeys_count={len(salesforce_ready_data)}\n")
                  f.write(f"status=success\n")
                  f.write(f"results={json.dumps(assembly_response)}\n")
                  
          except Exception as e:
              print(f"Error during journey assembly: {str(e)}")
              
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"journeys_count=0\n")
                  f.write(f"status=error\n")
                  f.write(f"error={str(e)}\n")
          EOF

      - name: Upload Assembly Results
        uses: actions/upload-artifact@v4
        with:
          name: journey-assembly-results
          path: journey_assembly_results.json
          retention-days: 30

  salesforce-sync:
    name: Sync Journeys to Salesforce
    runs-on: ubuntu-latest
    needs: [check-system-status, journey-assembly]
    if: needs.journey-assembly.outputs.assembly_status == 'success'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Journey Assembly Results
        uses: actions/download-artifact@v4
        with:
          name: journey-assembly-results

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Dependencies
        run: |
          pip install requests python-dateutil

      - name: Authenticate with Salesforce
        id: sf-auth
        env:
          SALESFORCE_LOGIN: ${{ secrets.SALESFORCE_LOGIN }}
          SALESFORCE_DOMAIN: ${{ vars.SALESFORCE_DOMAIN }}
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          
          print("Authenticating with Salesforce using fixed redirect handling...")
          
          # Configure session for manual redirect handling
          session = requests.Session()
          
          # Get credentials
          login_data = os.getenv('SALESFORCE_LOGIN', '').strip()
          domain = os.getenv('SALESFORCE_DOMAIN', 'login')
          
          if not login_data:
              print("Missing SALESFORCE_LOGIN secret")
              exit(1)
          
          try:
              login_json = json.loads(login_data)
              username = login_json.get('username')
              password = login_json.get('password')
              security_token = login_json.get('security_token', '')
              client_id = login_json.get('client_id', '')
              client_secret = login_json.get('client_secret', '')
          except Exception as e:
              print(f"Error parsing SALESFORCE_LOGIN: {str(e)}")
              exit(1)
          
          if not all([username, password, client_id, client_secret]):
              print("Missing required credentials")
              exit(1)
          
          print(f"Parsed credentials for user: {username}")
          print(f"Client ID present: {'Yes' if client_id else 'No'}")
          print(f"Security token present: {'Yes' if security_token else 'No'}")
          
          # OAuth data
          auth_data = {
              'grant_type': 'password',
              'client_id': client_id,
              'client_secret': client_secret,
              'username': username,
              'password': password + security_token
          }
          
          headers = {
              'Content-Type': 'application/x-www-form-urlencoded',
              'Accept': 'application/json'
          }
          
          # Try different URLs with proper redirect handling
          auth_urls = [
              f"https://{domain}.trailblaze.lightning.force.com/services/oauth2/token",
              "https://login.salesforce.com/services/oauth2/token",
              "https://test.salesforce.com/services/oauth2/token"
          ]
          
          for auth_url in auth_urls:
              try:
                  print(f"Trying OAuth with redirect handling: {auth_url}")
                  
                  # Make initial request with redirects disabled
                  response = requests.post(auth_url, data=auth_data, headers=headers, allow_redirects=False, timeout=30)
                  
                  # Handle redirects manually while maintaining POST method
                  redirect_count = 0
                  max_redirects = 3
                  
                  while response.status_code in [301, 302, 303, 307, 308] and redirect_count < max_redirects:
                      redirect_count += 1
                      redirect_url = response.headers.get('Location')
                      
                      if not redirect_url:
                          print(f"Redirect without Location header")
                          break
                      
                      print(f"Following redirect #{redirect_count} to: {redirect_url}")
                      
                      # Use session.request() to maintain POST method on redirect
                      response = session.request('POST', redirect_url, data=auth_data, headers=headers, timeout=30)
                  
                  if response.status_code == 200:
                      try:
                          auth_result = response.json()
                          access_token = auth_result.get('access_token')
                          instance_url = auth_result.get('instance_url')
                          
                          if access_token and instance_url:
                              print(f"Successfully authenticated with Salesforce!")
                              print(f"Final URL: {response.url}")
                              print(f"Instance URL: {instance_url}")
                              
                              # Save auth info
                              auth_info = {
                                  "access_token": access_token,
                                  "instance_url": instance_url,
                                  "auth_method": "OAuth2 with Fixed Redirects",
                                  "auth_url": auth_url
                              }
                              
                              with open("sf_auth.json", "w") as f:
                                  json.dump(auth_info, f)
                              
                              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                                  f.write(f"auth_success=true\n")
                                  f.write(f"instance_url={instance_url}\n")
                              
                              print("Authentication successful!")
                              exit(0)
                          else:
                              print("Missing access_token or instance_url in response")
                              
                      except json.JSONDecodeError:
                          print(f"Invalid JSON response: {response.text[:200]}")
                          
                  else:
                      print(f"Failed with status {response.status_code}")
                      print(f"Response headers: {dict(response.headers)}")
                      
                      try:
                          error_data = response.json()
                          print(f"Error: {error_data.get('error', 'Unknown')}")
                          print(f"Description: {error_data.get('error_description', 'No description')}")
                      except:
                          print(f"Response text: {response.text[:300]}")
                      
              except Exception as e:
                  print(f"Exception with {auth_url}: {str(e)}")
                  continue
          
          print("\nAll authentication attempts failed")
          print("Issue may be with Trailhead playground OAuth support")
          
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"auth_success=false\n")
          exit(1)
          EOF

      - name: Import Data to Salesforce
        id: import-data
        if: steps.sf-auth.outputs.auth_success == 'true'
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          
          print("Importing journey data to Salesforce...")
          
          # Load auth info
          with open("sf_auth.json", "r") as f:
              auth_info = json.load(f)
          
          access_token = auth_info["access_token"]
          instance_url = auth_info["instance_url"]
          
          # Load journey data from assembler format
          with open("journey_assembly_results.json", "r") as f:
              assembler_response = json.load(f)
          
          # Use the assembler response format directly
          journey_data = assembler_response

          # Debug: Print payload structure
          print("DEBUG: Payload structure being sent to Salesforce:")
          print(f"Available keys: {list(journey_data.keys())}")
          print(f"Status: {journey_data.get('status')}")
          print(f"Processed journeys: {journey_data.get('processed_journeys')}")
          
          if journey_data.get('salesforce_ready_data'):
              print(f"Salesforce ready data count: {len(journey_data['salesforce_ready_data'])}")
              print("First journey sample:")
              print(json.dumps(journey_data['salesforce_ready_data'][0], indent=2)[:500])
          else:
              print("ERROR: No salesforce_ready_data in payload!")
              print("Full payload structure:")
              print(json.dumps(journey_data, indent=2)[:1000])
                    
          # Prepare API call
          import_url = f"{instance_url}/services/apexrest/attribution/import/journeys"
          
          headers = {
              'Authorization': f'Bearer {access_token}',
              'Content-Type': 'application/json',
              'Accept': 'application/json'
          }
          
          try:
              print(f"Sending {len(journey_data['salesforce_ready_data'])} journeys to Salesforce...")
              print(f"API Endpoint: {import_url}")
              print(f"Data Format: Customer Journey Assembler format")
              
              response = requests.post(
                  import_url,
                  json=journey_data,
                  headers=headers,
                  timeout=120
              )
              
              if response.status_code == 200:
                  result = response.json()
                  
                  if result.get('success', False):
                      print(f"Successfully imported to Salesforce!")
                      print(f"Processed: {result.get('totalProcessed', 0)}")
                      print(f"Success: {result.get('successCount', 0)}")
                      print(f"Errors: {result.get('errorCount', 0)}")
                      
                      if result.get('errors'):
                          print("Import errors:")
                          for error in result['errors'][:3]:  # Show first 3 errors
                              print(f"   - {error}")
                      
                      # Save detailed results
                      with open("import_results.json", "w") as f:
                          json.dump(result, f, indent=2)
                      
                      # Set outputs
                      with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                          f.write(f"import_success=true\n")
                          f.write(f"journeys_imported={result.get('successCount', 0)}\n")
                          f.write(f"errors_count={result.get('errorCount', 0)}\n")
                      
                  else:
                      print(f"Salesforce import failed: {result.get('message', 'Unknown error')}")
                      print(f"Errors: {result.get('errors', [])}")
                      
                      with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                          f.write(f"import_success=false\n")
                      exit(1)
                      
              else:
                  print(f"HTTP Error {response.status_code}: {response.text}")
                  
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write(f"import_success=false\n")
                  exit(1)
                  
          except Exception as e:
              print(f"Import error: {str(e)}")
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"import_success=false\n")
              exit(1)
          EOF
          
      - name: Verify Import Success
        if: steps.import-data.outputs.import_success == 'true'
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          
          print("Verifying Salesforce import...")
          
          # Load auth info
          with open("sf_auth.json", "r") as f:
              auth_info = json.load(f)
          
          access_token = auth_info["access_token"]
          instance_url = auth_info["instance_url"]
          
          # Check import status
          status_url = f"{instance_url}/services/apexrest/attribution/import/status"
          
          headers = {
              'Authorization': f'Bearer {access_token}',
              'Content-Type': 'application/json'
          }
          
          try:
              response = requests.get(status_url, headers=headers, timeout=30)
              
              if response.status_code == 200:
                  status = response.json()
                  
                  print("Current Salesforce Status:")
                  print(f"   Total Journeys: {status.get('total_journeys', 0)}")
                  print(f"   Total Touchpoints: {status.get('total_touchpoints', 0)}")
                  print(f"   B2C Journeys: {status.get('b2c_journeys', 0)}")
                  print(f"   B2B Journeys: {status.get('b2b_journeys', 0)}")
                  print(f"   Converted Journeys: {status.get('converted_journeys', 0)}")
                  print(f"   Updated Journeys: {status.get('updated_journeys', 0)}")
                  print(f"   Last Import: {status.get('last_import', 'Unknown')}")
                  
              else:
                  print(f"Could not verify status: HTTP {response.status_code}")
                  print(f"Response: {response.text[:200]}")
                  
          except Exception as e:
              print(f"Verification error: {str(e)}")
          EOF

      - name: Upload Import Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: salesforce-import-results
          path: |
            journey_assembly_results.json
            import_results.json
            sf_auth.json
          retention-days: 7

      - name: Update Workflow Summary
        if: always()
        run: |
          if [[ "${{ steps.import-data.outputs.import_success }}" == "true" ]]; then
            echo "**Salesforce Import**: Successfully imported ${{ steps.import-data.outputs.journeys_imported }} journeys" >> $GITHUB_STEP_SUMMARY
            echo "**Journey IDs**: UUID-based format (journey_abc123)" >> $GITHUB_STEP_SUMMARY
            echo "**Upsert Logic**: Updates existing records, inserts new ones" >> $GITHUB_STEP_SUMMARY
            echo "**Errors**: ${{ steps.import-data.outputs.errors_count }} import errors" >> $GITHUB_STEP_SUMMARY
            echo "**Ready**: Attribution models can now process imported data" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Salesforce Import**: Failed to import journey data" >> $GITHUB_STEP_SUMMARY
            echo "**Action**: Check import logs for error details" >> $GITHUB_STEP_SUMMARY
          fi
          
  workflow-summary:
    name: Workflow Summary
    runs-on: ubuntu-latest
    needs: [check-system-status, data-collection, journey-assembly, salesforce-sync]
    if: always()  # Run even if some jobs fail
    
    steps:
      - name: Generate Workflow Summary
        run: |
          echo "# Journey Assembly Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "**Execution Time:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸ“Š Workflow Results" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| System Check | ${{ needs.check-system-status.result }} | System Enabled: ${{ needs.check-system-status.outputs.system_enabled }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Data Collection | ${{ needs.data-collection.result }} | 8 Channels Processed |" >> $GITHUB_STEP_SUMMARY
          echo "| Journey Assembly | ${{ needs.journey-assembly.result }} | Journeys: ${{ needs.journey-assembly.outputs.journeys_assembled }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Salesforce Sync | ${{ needs.salesforce-sync.result }} | Records Synced |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ðŸ”§ Fixed Issues" >> $GITHUB_STEP_SUMMARY
          echo "- **Journey IDs**: Now using UUID format (journey_abc123) instead of sequential" >> $GITHUB_STEP_SUMMARY
          echo "- **Duplicate Prevention**: Upsert logic prevents duplicate key errors" >> $GITHUB_STEP_SUMMARY
          echo "- **Data Format**: Compatible with Customer Journey Assembler output" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## Next Scheduled Run" >> $GITHUB_STEP_SUMMARY
          echo "**Every 3 days at 3:00 AM Amsterdam time**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## System Control" >> $GITHUB_STEP_SUMMARY
          echo "- Use 'Manual System Control' workflow to enable/disable processing" >> $GITHUB_STEP_SUMMARY
          echo "- Set repository variables: JOURNEY_ASSEMBLY_ENABLED, IMMEDIATE_STOP" >> $GITHUB_STEP_SUMMARY
          echo "- Emergency stop available via workflow dispatch" >> $GITHUB_STEP_SUMMARY
